# Model Evaluation: meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo

**Date:** 2025-11-30
**Test Set:** 21 queries

## Results Summary

| Method | Accuracy | Execution Errors | Notes |
|--------|----------|------------------|-------|
| Smart MAGIC | 12/21 (57.1%) | 1 | |
| Smart MAGIC + Guidelines | 12/21 (57.1%) | 1 | |
| Smart MAGIC + Retry | 12/21 (57.1%) | 0 | |

## Comparison with Llama 3.1 8B

| Method | Llama 3.1 8B | Meta-Llama-3.1-70B-Instruct-Turbo | Difference |
|--------|--------------|----------------------------------|------------|
| Smart MAGIC | 52.4% | 57.1% | +4.7pp |
| Smart MAGIC + Guidelines | 57.1% | 57.1% | +0.0pp |
| Smart MAGIC + Retry | 47.6% | 57.1% | +9.5pp |

## FinSQL Results

*To be evaluated*

