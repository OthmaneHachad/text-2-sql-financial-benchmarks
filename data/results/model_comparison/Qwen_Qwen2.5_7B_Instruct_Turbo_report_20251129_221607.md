# Model Evaluation: Qwen/Qwen2.5-7B-Instruct-Turbo

**Date:** 2025-11-29
**Test Set:** 21 queries

## Results Summary

| Method | Accuracy | Execution Errors | Notes |
|--------|----------|------------------|-------|
| Smart MAGIC | 7/21 (33.3%) | 1 | |
| Smart MAGIC + Guidelines | 9/21 (42.9%) | 0 | |
| Smart MAGIC + Retry | 8/21 (38.1%) | 0 | |

## Comparison with Llama 3.1 8B

| Method | Llama 3.1 8B | Qwen2.5-7B-Instruct-Turbo | Difference |
|--------|--------------|--------------------------|------------|
| Smart MAGIC | 52.4% | 33.3% | -19.1pp |
| Smart MAGIC + Guidelines | 57.1% | 42.9% | -14.2pp |
| Smart MAGIC + Retry | 47.6% | 38.1% | -9.5pp |

## FinSQL Results

*To be evaluated*

